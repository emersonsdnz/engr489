\documentclass{article}

\usepackage{fullpage}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{siunitx}
\usepackage{fancyvrb}
\usepackage{hyperref}
\hypersetup{
colorlinks,
citecolor=black,
filecolor=black,
linkcolor=black,
urlcolor=black
}
\usepackage{circuitikz}
\ctikzset{logic ports = ieee}
\usepackage{graphicx}
\graphicspath{{./images}}

\title{\textbf{Polar Codes on an FPGA}\\ENGR489 Project Proposal}
\author{Emerson Swanson-Dobbs}
\date{}

\begin{document}
\maketitle

\section*{Coding Theory}
When communicating data over a wireless channel, there is a possibility that the data will be corrupted due to noise. Coding theory looks to answer the question of how to best encode data to minimize errors and maximize transmission rate. Claude Shannon's theorem on the existence of good codes states that it is possible to transmit nearly error-free through a noisy channel so long as you transmit below the maximum capacity of the channel.

\section*{Polar Codes}

One recently proposed (in 2009) coding method is polar codes. They work on recursively applying a kernel to transform the physical channel into a number of ``virtual channels''. These virtual channels with either be perfectly reliable (transmit data with no chance of error) or perfectly unreliable (the output of the channel is uncorrelated with the input).

Polar codes are exciting because they are the first code that can provably reach the capacity of transmission over a noisy channel. Even better, they can be encoded and decoded in \(\mathcal{O}(n\log{n})\) time. However, some challenges prevent them being used practically. Their great theoretical performance also doesn't hold when a finite block length (amount of data sent) is used. The algorithm for decoding them is also rather complicated.

\section*{Implementation}




\end{document}